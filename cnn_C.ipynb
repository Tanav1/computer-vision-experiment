{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMTlqT1hA7OS0pChpCSbDbb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b7ldPmNQvjSe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "%%capture\n",
        "!pip install keras_tuner\n",
        "!pip install tensorflow\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import (\n",
        "    load_model,\n",
        "    clone_model\n",
        ")\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "s = userdata.get('ghkey')\n",
        "with open('./github_token', 'wb') as f:\n",
        "  f.write(bytes(s, 'utf'))\n",
        "!rm -rf ./207_final\n",
        "!git clone --depth 1 https://oauth2:$(cat ./github_token)@github.com/numbersrcool/207_final.git\n",
        "!rm ./github_token\n",
        "\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIyM4f6zyRZH",
        "outputId": "ec857fa4-004a-4137-95f8-a253e2b482ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '207_final'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 45 (delta 6), reused 30 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (45/45), 106.26 MiB | 15.41 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "207_final  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "b = userdata.get('bucket')\n",
        "with open('./.bucket', 'wb') as f:\n",
        "  f.write(bytes(b, 'utf'))\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!rm -rf data/\n",
        "!gsutil cp gs://$(cat /content/.bucket)/207_final.zip  /content/\n",
        "!unzip 207_final.zip\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tv4Qbifiv9Az"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 207_final\n",
        "!pwd"
      ],
      "metadata": {
        "id": "I9IOR9uhwQe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cd0d15-c1ae-4326-ed39-b2c9e7594f79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/207_final\n",
            "/content/207_final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env MIDS_207_DATA_PATH=../data\n",
        "\n",
        "from datasets import (\n",
        "    training,\n",
        "    validation,\n",
        "    TRAIN_BATCH_SIZE,\n",
        "    TRAIN_NUM_BATCHES,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2qDqY6P6uXz",
        "outputId": "0268c752-6b38-48a0-a0f3-fefba9038cac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MIDS_207_DATA_PATH=../data\n",
            "loading data from ../data...\n",
            "splitting data into train, val, test...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Motivation: a CNN model with only 1 but many filters and either average or max pooling.\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from models import (\n",
        "    NUM_CLASSES,\n",
        "    INPUT_SHAPE,\n",
        ")\n",
        "\n",
        "FILTERS = 2048\n",
        "KERNEL_SIZE = 2\n",
        "LR = 1e-3\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Input(INPUT_SHAPE))\n",
        "\n",
        "model.add(layers.Conv2D(\n",
        "    filters=FILTERS,\n",
        "    kernel_size=KERNEL_SIZE,\n",
        "    activation='relu'\n",
        "))\n",
        "model.add(layers.AveragePooling2D(pool_size=(8, 8)))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(\n",
        "    units=256,\n",
        "    activation='relu'\n",
        "))\n",
        "\n",
        "model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "lAdDRIlB9rPE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(\n",
        "        learning_rate=LR\n",
        "    ),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "0r1r1AVh4txu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "kOTVUOcbI1Zy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training.data,\n",
        "    epochs=TRAIN_NUM_BATCHES,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    validation_data=validation.data,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB2TotKqI35c",
        "outputId": "a9b17161-fc0d-41ce-e4b8-b4efac859427"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 420ms/step - accuracy: 0.3955 - loss: 186.2537 - val_accuracy: 0.9688 - val_loss: 0.1246 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 407ms/step - accuracy: 0.9766 - loss: 0.1089 - val_accuracy: 0.9891 - val_loss: 0.0390 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 405ms/step - accuracy: 0.9939 - loss: 0.0287 - val_accuracy: 0.9844 - val_loss: 0.0504 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 404ms/step - accuracy: 0.9846 - loss: 0.0716 - val_accuracy: 0.9812 - val_loss: 0.1069 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 407ms/step - accuracy: 0.9945 - loss: 0.0417 - val_accuracy: 0.9969 - val_loss: 0.0088 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 407ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0032 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 403ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 403ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 404ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0023 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = clone_model(model)\n",
        "tf.keras.backend.clear_session()\n",
        "# Unclear if these are mutated from the last call, so we'll just recreate.\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "\n",
        "# Compile from the same config\n",
        "baseline_model.compile_from_config(model.get_compile_config())\n"
      ],
      "metadata": {
        "id": "U6GKf0TkMig3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = baseline_model.fit(training.baseline_data,\n",
        "    epochs=TRAIN_NUM_BATCHES,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    validation_data=validation.baseline_data,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOrrWOcwMwkx",
        "outputId": "79042a1e-baf9-477b-9746-09aa1ff75264"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 354ms/step - accuracy: 0.5146 - loss: 58.9740 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 2.5000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 340ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 2.0782e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 1.3247e-04 - val_accuracy: 1.0000 - val_loss: 3.5491e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 339ms/step - accuracy: 1.0000 - loss: 3.2684e-05 - val_accuracy: 1.0000 - val_loss: 1.4039e-05 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model.save('/content/cnn_C_baseline.keras')\n",
        "model.save('/content/cnn_C.keras')"
      ],
      "metadata": {
        "id": "p0U_cT6XNX-1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd /content\n",
        "# !gsutil cp cnn_C.keras gs://$(cat /content/.bucket)/\n",
        "!gsutil cp cnn_C_baseline.keras gs://$(cat /content/.bucket)/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpX3T0jJOBZz",
        "outputId": "193b4993-7ba2-4f12-deab-3b87c501154c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://cnn_C_baseline.keras [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/  1.3 GiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/\n",
            "Operation completed over 1 objects/1.3 GiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -laht /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P47VIr1mPIAX",
        "outputId": "a8f6860a-9fb7-4590-d9d8-34b35235fae4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.9G\n",
            "-rw-r--r--  1 root root 1.4G Dec  7 22:22 cnn_C.keras\n",
            "drwxr-xr-x  1 root root 4.0K Dec  7 22:22 .\n",
            "-rw-r--r--  1 root root 1.4G Dec  7 22:22 cnn_C_baseline.keras\n",
            "drwxr-xr-x 37 root root 4.0K Dec  7 20:54 data\n",
            "-rw-r--r--  1 root root 268M Dec  7 20:54 207_final.zip\n",
            "drwxr-xr-x  1 root root 4.0K Dec  7 20:54 .config\n",
            "-rw-r--r--  1 root root   44 Dec  7 20:53 .bucket\n",
            "drwxr-xr-x  8 root root 4.0K Dec  7 20:53 207_final\n",
            "drwxr-xr-x  1 root root 4.0K Dec  7 20:33 ..\n",
            "drwxr-xr-x  1 root root 4.0K Dec  5 14:24 sample_data\n"
          ]
        }
      ]
    }
  ]
}